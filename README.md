# DIVERS-Bench
### Evaluating Language Identification Across Domain Shifts and Code-Switching
## Abstract
> Language Identification (LID) is a core task in multilingual NLP, yet current
systems often overfit to clean, monolingual data. This work introduces DIVERS-
BENCH a comprehensive evaluation of state-of-the-art LID models across diverse
domains - including speech transcripts, web text, social media texts, childrenâ€™s
stories, and code-switched text. Our findings reveal that while models achieve high
accuracy on curated datasets, performance degrades sharply on noisy and informal
inputs. We also introduce DIVERS-CS, a diverse code-switching benchmark
dataset spanning 10 language pairs, we show that existing models struggle to detect
multiple languages within the same sentence. These results highlights the need for
more robust and inclusive LID systems in real-world settings.
